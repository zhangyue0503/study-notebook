<html>
<head>
  <title>Hadoop实战</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/608449 (zh-CN, DDL); Windows/10.0.0 (Win64); EDAMVersion=V2;"/>
  <style>
	body, td {
	  font-family: 微软雅黑;
	  font-size: 12pt;
	}
  </style>
</head>
<body>
<a name="2041"/>
<h1>Hadoop实战</h1>

<div>
<span><div><span style="font-size: 24px;"><b>一、Hadoop简介</b></span></div><div><b>A.什么是Hadoop</b></div><div>1.Hadoop是一个开源分布式计算平台，以HDFS（Hadoop Distributed Filesystem，Hadoop分布式文件系统）和MapReduce为核心，为用户提供了系统底层细节透明的分布式基础架构</div><div>2.使用HDFS分布式存储方式，提高了读写速度，扩大了存储容量，采用MapReduce来整合分布式文件系统上的数据，可以保证分析和处理数据的高效，还采用存储冗余数据的方式保证了数据的安全性；HDFS的高容错特性，使得Hadoop可以部署在低廉的计算机集群中，同时不限于某个操作系统</div><div>3.Hadoop优势：高可靠性、高扩展性、高效性、高容错性</div><div><br/></div><div><b>B.Hadoop项目及其结构</b></div><div>1.Core/Common，是为Hadoop其他子项目提供支持的常用工具，包括FileSystem、RPC和串行化库</div><div>2.Avro，用于数据序列化的系统</div><div>3.MapReduce，是一种编程模型，用于大规模数据集（大于1TB）的并行去处</div><div>4.HDFS，分布式文件系统</div><div>5.Chukwa，开源的数据收集系统，用于监控和分析大型分布式系统的数据</div><div>6.Hive，是一个建立在Hadoop基础之上的数据仓库，提供了一些用于数据整理、特殊查询和分析存储在Hadoop文件中的数据集工具</div><div>7.HBase，分布式的、面向列的开源数据库</div><div>8.Pig，是一个对大型数据集进行分析和评估的平台</div><div><br/></div><div><b>C.Hadoop的体系结构</b></div><div>1.HDFS采用了主从（Master/Slave）结构模型，一个集群由一个NameNode和若干个DataNode组成</div><ul><li>NameNode：主服务器，管理文件系统的命名空间和客户端对文件的访问操作，执行文件系统的命名空间操作，也负责数据块到具体DataNode的映射</li><li>DataNode：管理存储的数据，文件被分成若干个数据块，这些个数据块存放在一组DataNode上，负责处理文件系统客户端的文件读写请求</li></ul><div>2.MapReduce是由一个单独运行在主节点上的JobTracker和运行在每个集群从节点上的TaskTracker共同组成</div><div><br/></div><div><b>D.Hadoop与分布式开发</b></div><div>1.Hadoop是分布式软件系统中文件系统这一层的软件，实现了分布式文件系统和部分分布式数据库的功能</div><div>2.MapReduce编辑模型的原理是：利用一个输入的key/value对集合来产生一个输出的key/value对集合，三个主要函数：map、reduce、main</div><div><br/></div><div><b>E.Hadoop计算模型——MapReduce</b></div><div>1.一个MapReduce作业（job）通常会把输入的数据集切分为若干个独立的数据块，由map任务（task）以完全并行 的方式处理它们</div><div><br/></div><div><b>F.Hadoop的数据管理</b></div><div>1.HDFS三个重要的组件：NameNode、DataNode、Client，Client是需要获取分布式文件系统文件的应用程序</div><div>2.HBase在分布式集群上主要领先由HRegion、HMaster、HClient组成的体系结构从整体上管理数据</div><div>3.Hive是建立在Hadoop上的数据仓库基础架构，它提供了一系列的工具，用来进行数据提取、转化、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制</div><div><br/></div><div><span style="font-size: 24px;"><b>二、Hadoop的安装与配置</b></span></div><div>1.hadoop-3.0.0-alpha3，默认locahost:9870和localhost:50090</div><div><br/></div><div><span style="font-size: 24px;"><b>三、Hadoop应用案例分析</b></span></div><div>1.大规模的数据处理经常分为三个不同的任务：数据收集、数据准备和数据表示</div><ul><li>数据准备，通常被认为是提取、转换和加载（Extract Transform Load, ETL）数据的阶段，或者认为这个阶段是数据工厂</li><li>数据表示阶段一般指的是数据仓库，数据仓库存储了客户所需要的产品，客户会根据需要选取合适的产品</li></ul><div><br/></div><div><span style="font-size: 24px;"><b>四、MapReduce计算模型</b></span></div><div><b>A.MapReduce计算模型</b></div><div>1.在Hadoop中，用于执行MapReduce任务的机器角色：一个是JobTracker，用于调度工作，一个集群中只有一台；另一个是TaskTracker，用于执行工作；</div><div>2.JobTracker调度任务给TaskTracker，TaskTracker执行任务时，会返回进度报告。JobTracker则会记录进度的进行状况，如果某个TaskTracker上的任务执行失败，那么JobTracker会把这个任务分配给另一台TaskTracker，直到任务执行完成</div><div><br/></div><div><b>B.Hadoop流</b></div><div>1.Hadoop流提供了一个API，允许用户使用任何脚本语言编写map函数或reduce函数，使用UNIX标准流作为程序与Hadoop之间的接口</div><div>2.Hadoop Pipes提供了一个在Hadoop上运行C++程序的方法，pipes使用的是Sockets</div><div><br/></div><div><span style="font-size: 24px;"><b>五、开发MapReduce应用程序</b></span></div><div>1.Hadoop自带的网络用户界面：http://xxx:50030</div><div>2.性能调优：</div><ul><li>输入的文件尽量采用大文件，避免使用小文件</li><li>考虑压缩文件</li></ul><div>3.MapReduce工作流</div><ul><li>Mapper通常用来处理输入格式转化、投影（选择相关的字段）、过滤（去掉那些不感兴趣的记录）等</li><li>Hadoop工作流调度器（HWS）作为一个服务器，允许客户端提交一个工作流给调度器</li></ul><div><br/></div><div><span style="font-size: 24px;"><b>六、MapReduce引用案例</b></span></div><div><br/></div><div><span style="font-size: 24px;"><b>七、MapReduce工作机制</b></span></div><div><b>A.MapReduce作业的执行流程</b></div><div>1.MapReduce任务的执行总流程：代码编写-&gt;作业配置-&gt;作业提交-&gt;Map任务的分配和执行-&gt;处理中间结果-&gt;Reduce任务的分配和执行-&gt;作业完成，每个任务又包括输入准备-&gt;任务执行-&gt;输出结果</div><div>2.4个独立实体：</div><ul><li>客户端（client）：编写MapReduce代码，配置作业，提交作业</li><li>JobTracker：初始化作业，分配作业，与TaskTracker通信，协调整个作业的执行</li><li>TaskTracker：保持JobTracker的通信，在分配 的数据片段上执行Map或Reduce任务，可以包含多个TaskTracker</li><li>HDFS：保存作业的数据、配置信息，保存作业结果</li></ul><div><br/></div><div><b>B.错误处理机制</b></div><div>1.在集群中，任何时候都只有唯一一个JobTracker，所以JobTracker故障就是单点故障，一般是创建多个备用JobTracker节点</div><div>2.TaskTracker故障很正常，会由MapReduce处理</div><div><br/></div><div><b>C.作业调度机制</b></div><div>1.Hadoop默认FIFO调度器，还提供了支持多用户服务和集群资源公平共享的调度器，即公平调度器（Fair Scheduler Guide）和容量调度器（Capacity Scheduler Guide）</div><div>2.shuffle过程包含在map和reduce两端中，map端是对map的结果进行划分、排序和分割，然后将属于同一个划分的输出合并在一起；reduce端又会将各个map送来的属于同一个划分 的输出进行合并，然后对合并结果进行排序，最后交给reduce处理</div><div><br/></div><div><b>D.任务执行</b></div><div>1.推测式执行，指当作业的所有任务都开始运行时，JobTracker会统计所有任务的平均进度，如果某个任务所在的TaskTracker节点由于配置比较低或CPU负载过高，导致任务执行的速度比总体任务的平均速度慢，此时JobTracker就会启动一个新的备份任务，原有任务和新任务哪个先执行完就把另一个kill掉，缺点是对于代码缺陷导致的问题，备份并不能解决</div><div>2.任务JVM重用、跳过坏记录</div><div><br/></div><div><span style="font-size: 24px;"><b>八、Hadoop I/O操作</b></span></div><div>1.Hadoop采用CRC-32（Cyclic Redundancy Check，循环冗余校验，其中的32指生成 的校验和是32位的）的方式检查数据完整性</div><div>2.Hadoop使用RPC来实现进程间通信，使用Writables序列化机制</div><div><br/></div><div><span style="font-size: 24px;"><b>九、HDFS详解</b></span></div><div><b>A.HDFS简介</b></div><div>1.特点：处理超大文件；流式访问数据；运行于廉价的商用机器集群上；</div><div>2.局限性：不适合低延迟数据访问；无法高效存储大量小文件；不支持多用户写入及任意修改文件</div><div><br/></div><div><b>B.HDFS体系结构</b></div><div>1.HDFS分布式文件系统中的文件也被划分成块进行存储，它是文件存储处理的单元，默认块为64MB</div><div>2.NameNode就是Master管理集群中的执行调度，DataNode就是Worker具体任务的执行节点</div><div>3.一个HDFS集群是由一个NameNode和一定数目的DataNodes组成的，一个文件其实被分成了一个或多个数据块，这些块存储在一组DataNode上</div><div><br/></div><div><span style="font-size: 24px;"><b>十、Hadoop的管理</b></span></div><div>1.监控工具：Metrics、Ganglia</div><div>2.备份工具：distcp</div><div>3.Hadoop管理命令：dfsadmin，获取HDFS的状态信息；fsck，检测文件块</div><div><br/></div><div><span style="font-size: 24px;"><b>十一、Hive详解</b></span></div><div>1.Hive是一个基于Hadoop文件系统上的数据仓库架构，它为数据仓库提供了许多功能：数据ETL（抽取、转换和加载）工具、数据存储管理和大型数据集的查询与分析能力，同时Hive还定义了类SQL语言——Hive QL</div><div>2.Hive中主要包含四类数据模型：表（Table）、外部表（External Table）、分区（Partition）、桶（Bucket）</div><div><br/></div><div><span style="font-size: 24px;"><b>十二、HBase详解</b></span></div><div><b>A.HBase简介</b></div><div>1.特点：向下提供了存储，向上提供了运算</div><div><br/></div><div><b>B.HBase的基本操作</b></div><div>1.单机模式可以直接运行，分布式模式需要Hadoop</div><div><br/></div><div><b>C.HBase体系结构</b></div><div>1.HBase的服务器体系结构遵从简单的主从服务器架构，由HRegion服务器群和HBase Master服务器构成。HBase Master服务器负责管理所有的HRegion服务器，而HBase中所有的服务器都是通过ZooKeeper来进行协调，并处理HBase服务器运行期间可能遇到的错误的。HBase Master Server本身并不存储HBase中的任何数据，HBase逻辑上的表可能会被划分成多个HRegion，然后存储到HRegion Server群中。HBase Master Server中存储的是从数据到HRegion Server的映射</div><div><br/></div><div><b>D.HBase数据模型</b></div><div>1.HBase是一个类似Bigtable的分布式数据库，它是一个稀疏的长期存储的（存在硬盘上）、多维度的、排序的映射表。这张表的索引是行关键字、列关键字和时间戳。HBase中的数据都是字符串，没有类型</div><div>2.列名字的格式是“&lt;family&gt;:&lt;qualifier&gt;”，都是由字符串组成的，每一张表有一个一列族（family）集合，这个集合是固定不变的，只能通过改变表结构来改变；写操作是锁行的；所有数据库更新都有一个时间戳标记，每个更新都是一个新的版本，HBase会保留一定数量的版本</div><div><br/></div><div><b>E.HBase与RDBMS</b></div><div>1.只有简单的字符串类型</div><div>2.只有很简单的插入、查询、删除、清空等操作，表和表之间是分离的，没有复杂的表间关系</div><div>3.是基于列存储的，每个列族都由几个文件保存</div><div>4.更新操作会保留旧版本，不是传统关系数据库里的替换修改</div><div>5.能够轻易地增加或减少硬件数量，对错误兼容性高</div><div>6.适应海量存储和互联网应用的需要，利用廉价的硬件设备组建数据仓库，原本就是作为一个搜索引擎的一部分开发出来的</div><div><br/></div><div><span style="font-size: 24px;"><b>十三、Mahout详解</b></span></div><div><b>A.Mahout简介</b></div><div>1.Apache Mahout的主要目标是建立可伸缩的机器学习算法，这种可伸缩性是针对大规模的数据集而言的</div><div><br/></div><div><b>B.Mahout中的聚类和分类</b></div><div>1.Mahout中三种向量：稠密向量（DenseVector）、随机访问向量（RandomAccessSparseVector）和序列访问向量（SequentialAccessSparseVector）</div><div><br/></div><div><span style="font-size: 24px;"><b>十四、Pig详解</b></span></div><div><b>A.Pig简介</b></div><div>1.Pig包括用来描述数据分析程序的高级程序语言，以及对这些程序进行评估的基础结构。突出的特点就是它的结构经得起大量并行 任务，使得它能够对大规模数据集进行处理</div><div>2.Pig使用Pig Latin语言，类似SQL，偏重查询</div><div><br/></div><div><span style="font-size: 24px;"><b>十五、Zookeeper详解</b></span></div><div><b>A.ZooKeeper简介</b></div><div>1.ZooKeeper是一个为分布式应用所设计的开源协调服务，可以为用户提供同步、配置管理、分组和命名等服务</div><div>2.设计目标：</div><ul><li>简单化：允许分布式的进程通过共享体系的命名空间来进行协调，这个命名空间组织与标准的文件系统非常相似，它是由一些数据寄存器组成的</li><li>健壮性：组成ZooKeeper服务的服务器必须互相知道其他服务器的存在</li><li>有序性：可以为每一次更新操作赋予一个版本号，并且此版本号是全局有序的，不存在重复的情况</li><li>速度优势：在上千台机器节点上运行</li></ul><div><br/></div><div><b>B.ZooKeeper的Leader选举</b></div><div>1.ZooKeeper需要在所有的服务（可以理解为服务器）中选举出一个Leader，然后让这个Leader来负责管理集群，其他为Follower。当Leader出现故障时，ZooKeeper要能够快速地在Follower中选举出下一个Leader，这就是ZooKeeper的Leader机制</div><div><br/></div><div><b>C.ZooKeeper锁服务</b></div><div>1.在ZooKeeper中，完全分布的锁是全局同步的，也就是说，在同一时刻，不会有两个不同的客户端认为他们持有了相同的锁</div><div><br/></div><div><b>E.典型应用场景（网上找的）</b></div><div>1.统一命名服务</div><div>2.配置管理：配置信息完全可以交给 Zookeeper 来管理，将配置信息保存在 Zookeeper 的某个目录节点中，然后将所有需要修改的应用机器监控配置信息的状态，一旦配置信息发生变化，每台应用机器就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中</div><div>3.集群管理：实现方式都是在 Zookeeper 上创建一个 EPHEMERAL 类型的目录节点，然后每个 Server 在它们创建目录节点的父目录节点上调用 getChildren(String path, boolean watch) 方法并设置 watch 为 true，由于是 EPHEMERAL 目录节点，当创建它的 Server 死去，这个目录节点也随之被删除，所以 Children 将会变化，这时 getChildren上的 Watch 将会被调用，所以其它 Server 就知道已经有某台 Server 死去了。新增 Server 也是同样的原理</div><div>4.共享锁</div><div>5.队列管理</div><div><br/></div><div><span style="font-size: 24px;"><b>十六、Avro详解</b></span></div><div><b>A.Avro简介</b></div><div>1.Avro是一个数据序列化的系统，可以将数据结构或对象转化成便于存储或传输的格式，特别是设计之初它可以用来支持数据密集型应用，适合于大规模数据的存储和交换</div><div>2.Avro模式是用JSON定义的，提供与Thrift和Protocol Buffers等系统相似的功能</div><div><br/></div><div><span style="font-size: 24px;"><b>十七、Chukwa详解</b></span></div><div><b>A.Chukwa简介</b></div><div>1.Chukwa能通过扩展处理大量的客户端请求，并且能汇聚多路客户端的数据流，采用的是流水式数据处理方式和模块化结构的收集系统，在每一个模块中有一个简单规范的接口</div><div><br/></div><div><b>B.Chukwa架构</b></div><div>1.有三个主要组成部分：</div><div>客户端(Agent)：使内部进程通信协议能够兼容处理本地的日志文件</div><div>收集器(Collector)和分离器(Demux)：利用了Collectors策略</div><div>HICC(Hadoop Infrastructure Care Center)：数据可视化页面</div><div><br/></div><div><span style="font-size: 24px;"><b>十八、Hadoop的常用插件与开发</b></span></div><div>1.Hadoop Studio</div><div>2.Hadoop Eclipse</div><div>3.Hadoop Streaming：帮助用户创建和运行一类特殊的MapReduce作业，这些作业由一些可执行文件或脚本文件充当mapper或reducer，也就是允许使用非Java语言</div><div>4.Hadoop Libhdfs：是一个基于C编程接口的为Hadoop分布式文件系统开发的JNI，提供了一个C语言接口以结合管理DFS文件和文件系统</div><div><br/></div><div><br/></div><div>/hadoopshizhan/</div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></span>
</div></body></html> 