<html>
<head>
  <title>软件测试52讲【极客时间】</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/608449 (zh-CN, DDL); Windows/10.0.0 (Win64); EDAMVersion=V2;"/>
  <style>
	body, td {
	  font-family: 微软雅黑;
	  font-size: 12pt;
	}
  </style>
</head>
<body>
<a name="1059"/>
<h1>软件测试52讲【极客时间】</h1>

<div>
<span><div><div><div><div>作为测试工程师，你的目标是要保证系统在各种应用场景下的功能是符合设计要求的，所以你需要考虑的测试用命就需要更多、更全面</div><div><br/></div><div>等价类划分方法，是将所有可能的输入数据划分成若干个子集，在每个子集中，如果任意一个输入数据对于揭露程序中潜在错误都具有同等效果，那么这样的子集就构成了一个等价类</div><div><br/></div><div>边界值分析方法，是选取输入、输出的边界值进行测试。因为通常大量的软件错误是发生在输入或输出范围的边界上，所以需要对边界值进行重点测试，通常选取正好等于、刚刚大于或刚刚小于边界的值作为测试数据</div><div><br/></div><div>显式功能性需求（Functional requirement）指的是软件本身需要实现的具体功能</div><div><br/></div><div>非功能性需求主要涉及安全性、性能以及兼容性三大方面</div><div><br/></div><div>所谓的“穷尽测试”是指包含了软件输入值和前提条件所有可能组合的测试方法，完成穷尽测试的系统里应该不残留任何未知的软件缺陷。在绝大多数的软件工程实践中，测试由于受限于时间成本和经济成本，是不可能去穷尽所有可能的组合的，而是采用基于风险驱动的模式，有所侧重地选择测试满园和设计测试用命，以寻求缺陷风险和研发成本之间的平衡</div><div><br/></div><div>“好的”测试用命一定是一个完备的集合，它能够覆盖所有等价类以及各种边界值，而跟能否发现缺陷无关，三个特征：</div><ul><li><div>1）整体完备性：一定是一个完备的整体，是有效测试用命组成的集合，能够完全覆盖测试需求</div></li><li><div>2）等价类划分的准确性：指的是对于每个等价类都能保证只要上一个输入测试通过，其他输入也一定测试通过</div></li><li><div>3）等价类集合的完备性：需要保证所有可能的边界值和边界条件都已经正确识别</div></li></ul><div><br/></div><div>对于大多数的软件测试而言，综合使用等价类划分、边界值分析和错误推测这三大类方法就足够了</div><div><br/></div><div>在具体的用例设计时，首先需要搞清楚每一个业务需求所对应的多个软件功能需求点，然后分析出每个软件功能需求点对应的多个测试需求点，最后再针对每个测试需求点设计测试用例</div><div><br/></div><div>从软件功能需求出发，全面地、无遗漏地识别出测试需求是至关重要的，这将直接关系到用例的测试覆盖率</div><div><br/></div><div>用例设计的三个独家“秘籍”：</div><ul><li><div>1）只有深入理解被测试软件的架构，你才能设计出“有的放矢”的测试用例集，去发现系统边界及系统集成上的潜在缺陷</div></li><li><div>2）必须深入理解被测试软件的设计与实现细节，深入理解软件内部的处理逻辑</div></li><li><div>3）需要引入需求覆盖率和代码覆盖率来衡量测试执行的完备性，并以此为依据来找出遗漏的测试点</div></li></ul><div><br/></div><div>单元测试是的，对软件中的最小可测试单元在与程序其他部分相隔离的情况下进行检查和验证的工作，这里的最小可测试单元通常是指函数或者类</div><div><br/></div><div>无论是开发语言还是脚本语言，都会有条件分支、循环处理和函数调用等最基本的逻辑控制，如果抛开代码需要实现的具体业务逻辑，仅看代码结构的话，你会发现所有的代码都是在对数据进行分类处理，每一次条件判定都是一次分类处理，嵌套的条件判定或者循环执行，也是在做分类处理</div><div><br/></div><div>要做到代码功能逻辑正确，必须做到分类正确并且完备无遗漏，同时每个分类的处理逻辑必须正确</div><div><br/></div><div>单元测试的用例是一个“输入数据”和“预计输出”的集合。你需要针对确定的输入，根据逻辑功能推算出正确的输出，并且以执行被测试代码的方式进行验证，用一句话概括就是“在明确了代码需要实现的逻辑功能的基础上，什么输入，应该产生什么输出”</div><div><br/></div><div>驱动代码（Driver）指调用被测函数的代码，在单元测试过程中，驱动模块通常包括调用被测函数前的数据准备、调用被测函数以及验证相关结果三个步骤</div><div><br/></div><div>桩代码的应用首先起到了隔离和补齐的作用，使被测代码能够独立编译、链接，并独立运行。同时，桩代码还具有控制被测函数执行路径的作用。三个原则：</div><ul><li><div>桩函数要具有与原函数完全相同的原形，仅仅是内部实现不同，这样测试代码才能正确链接到桩函数</div></li><li><div>用于实现隔离和补齐的桩函数比较简单，只需保持原函数的声明，加一个空的实现，目的是通过编译链接</div></li><li><div>实现控制遥桩函数是应用最广泛，要根据测试用例的需要，输出合适的数据作为被测函数的内部输入</div></li></ul><div><br/></div><div>Mock代码和桩代码的本质区别是测试期待毕析验证（Assert and Expectiation）：</div><ul><li><div>对于Mock代码来说，我们的关注点是Mock方法有没有被调用，以什么样的参数被调用，被调用的次数，以及多个Mock函数的先后调用顺序</div></li><li><div>对于桩代码来说，我们的关注点是利用Stub来控制被测函数的执行路径，不会去关注Stub是否被调用以及怎么样被调用</div></li></ul><div><br/></div><div>项目中如何开展单元测试：</div><ul><li><div>1）并不是所有的代码都要进行单元测试，通常只有底层模块或者核心模块的测试中才会采用单元测试</div></li><li><div>2）你需要确定单元测试框架的选型，这和开发语言相关</div></li><li><div>3）为了能够衡量单元测试的代码覆盖率，通常你还需要引入计算代码覆盖率的工具</div></li><li><div>4）最后需要把单元测试执行、代码覆盖率统计和持续集成流水线做集成，以确保每次代码递交，都会自动触发单元测试，并在单元测试执行过程中自动统计代码覆盖率，最后以“单元测试通过率”和“代码覆盖率”为标准来决定本次代码递交是否能够被接受</div></li></ul><div><br/></div><div>自动化测试的本质是先写一段代码，然后去测试另一段代码，所以实现自动化测试用例本身属于开发工作，需要投入大量的时间和精力，并且已经开发完成的用例还必须随着被测对象的改变而不断更新，你还需要为此付出维护测试用例的成本</div><div><br/></div><div>当你发现自动化测试用例的维护成本高于其节省的测试成本时，自动测试就失去了价值与意义，你也就需要在是否使用自动化测试上权衡取舍了</div><div><br/></div><div>什么项目适合自动化测试：</div><ul><li><div>1）需求稳定，不会频繁变更</div></li><li><div>2）研发和维护周期长，需要频繁执行回归测试</div></li><ul><li><div>软件产品比软件项目更适合做自动化测试</div></li><li><div>对于一些中长期项目，对比较稳定的软件功能进行自动化测试，对变动较大或者需求暂时不明确的功能进行手工测试，最终目标是20%的精力去覆盖80%的回归测试</div></li></ul><li><div>3）需要在多种平台上重复运行相同测试的场景</div></li><li><div>4）某些测试项目通过手工测试无法实现，或者手工成本太高</div></li><ul><li><div>对于所有性能和压力测试，很难通过手工方式实现</div></li></ul><li><div>5）被测软件的开发较为规范，能够保证系统的可测试性</div></li><ul><li><div>某些用例的自动化必须要求开发人员在产品中预留可测试性接口，否则后续的自动化会很难开展（如登录验证码）</div></li></ul><li><div>6）测试人员具有一定的编程能力</div></li></ul><div><br/></div><div>从广义上来说，单元测试阶段的“自动化”内涵不仅仅指测试用例执行的自动化，还应该包括：</div><ul><li><div>1）用例框架代码生成的自动化：如TestNG</div></li><li><div>2）部分测试输入数据的自动化生成：</div></li><li><div>3）自动桩代码的生成：单元测试开发者只需重点关注桩代码内的具体逻辑实现，以及桩代码的返回值</div></li><li><div>4）被测代码的自动化静态分析</div></li><li><div>5）测试覆盖率的自动统计与分析</div></li></ul><div><br/></div><div>代码级集成测试与单元测试最大的区别只是，代码级集成测试中被测函数内部调用的其他函数必须是真实的，不允许使用桩代码代替，而单元测试中允许使用桩代码来模拟内部调用的其他函数。互联网企业一般寻求系统复杂性的解耦，所以不会做代码级集成测试</div><div><br/></div><div>WebService测试的自动化不仅仅包括API测试用例执行的自动化，还包括：</div><ul><li><div>1）测试脚手架代码的自动仳生成</div></li><li><div>2）部分测试输入数据的自动生成</div></li><li><div>3）Response验证的自动化：自动 比较两次相同API调用的返回毕要，并自动识别出有差异的字段值，比较过程可以通过规则配置去诸如时间戳、会话ID等动态值</div></li><li><div>4）基于SoapUI或者Postman的自动化脚本生成</div></li></ul><div><br/></div><div>测试覆盖率通常被用来衡量测试的充分性和完整性，从广义的角度来讲，测试覆盖率主要分为两大类，一类是面向项目的需求覆盖率，一类是更偏向技术的代码覆盖率</div></div><div><br/></div><div>需求覆盖率是指测试对需求的覆盖程度，通常的做法是将每一条分解后的软件需求和对应的测试建立一对多的映射关系，最终目标是保证测试可以覆盖每个需求，以保证软件产品的质量</div><div><br/></div><div>代码覆盖率是指，至少被执行了一次的条目占整个条目数的百分比。如果“条目数”是语句，对应的就是代码行覆盖率；如果“条目数”是函数，对应的就是函数覆盖率；如果“条目数”是路径，那么对应的就是路径覆盖率</div><div><br/></div><div>三种代码覆盖率指标：</div><ul><li><div>1）行覆盖率又称为语句覆盖率，指已经被执行到的语句占总可执行语句 （不包含类似 C++的头文件声明、代码注释、空行等）的百分比。这是最常用也是要求最低的覆盖率指标。实际项目中通常会结合判定覆盖率或者条件覆盖率一起使用</div></li><li><div>2）判定覆盖又称分支覆盖，用以度量程序中每一个判定的分支是否都被测试到了，即代码中每个判断的取真分支和取假分支是否各被覆盖至少一次</div></li><li><div>3）条件覆盖指判定中的每个条件的可能取值至少满足一次，度量断定中的每个条件的结果TRUE和FALSE是否都被测试到了</div></li></ul><div><br/></div><div>统计代码覆盖率的根本目的是找出潜在的遗漏测试用例，并有针对性的进行补充，同时还可以识别出代码中那些由于需求变更等原因造成的不可达的废弃代码</div><div><br/></div><div>在软件企业中，只有单元测试阶段对代码覆盖率有较高的要求。因为从技术实现上讲，单元测试可以最大化地利用打桩技术来提高覆盖率。而如果想在集成测试或者GUI测试阶段将代码覆盖率提高到一定量级，那你所要付出的代价是巨大的，而且在很多情况下根本就实现不了</div><div><br/></div><div>高的代码覆盖率不一定双腿保证软件的质量，但是低的代码覆盖率一定不能保证软件的质量</div><div><br/></div><div>实现代码覆盖率的统计，最基本的方法就是注入（Instrumentation）。简单地说，注入就是在被测代码中自动插入用于覆盖率统计的探针（Probe）代码，并保证插入的探针代码不会给原代码带来任何影响</div><div><br/></div><div>好的缺陷报告绝对不是大量信息的堆叠，而是以高效的方式提供准确有用的信息：</div><ul><li><div>1）缺陷标题</div></li><ul><li><div>是对缺陷的概括性描述，通常采用“在什么情况下发生了什么问题”的模式</div></li><li><div>对“什么问题”的描述不仅要做到清晰简洁，最关键是要足够具体，切忌不能采用过于笼统的描述，清楚地表述发生问题时的上下文，也就是问题出现的场景</div></li><li><div>标题应该尽可能描述问题本质，而避免只停留在问题的表面</div></li><li><div>标题不宜过长，对缺陷更详细的描述应该放在“缺陷概述”里</div></li></ul><li><div>2）缺陷概述</div></li><ul><li><div>通常会提供更多概括性的缺陷本质与现象的描述，是标题的细化。通常是开发工程师打开缺陷报告后最先关注的内容，所以用清晰简短的语句将问题的本质描述清楚是关键</div></li></ul><li><div>3）缺陷影响</div></li><ul><li><div>决定了缺陷的优先级（Priority）和严重程度（Serverity），开发经理会以此为依据来决定修复该缺陷的优先级；而产品经理会以此为依据来衡量缺陷的严重程度，并决定是滞要等该缺陷被修复后才能发布产品</div></li></ul><li><div>4）环境配置</div></li><ul><li><div>详细描述测试环境的配置细节，为缺陷的重现提供必要的环境信息</div></li></ul><li><div>5）前置条件</div></li><ul><li><div>指测试步骤开始前系统应该处在的状态，其目的是减少缺陷重现步骤的描述</div></li></ul><li><div>6）缺陷重现步骤</div></li><ul><li><div>整个缺陷报告中的核心内容，目的在于用简洁的语言向开发工程师展示缺陷重现的具体操作步骤</div></li><li><div>操作步骤通常是从用户角度来描述的，每个步骤都应该是可操作并且是连贯的，所以往往会采用步骤列表的表现形式</div></li></ul><li><div>7）期望结果和实际结果</div></li><ul><li><div>当你描述期望结果时，需要说明应该发生什么，而不是什么不应该发生；而描述实际结果时，你应该说明发生了什么，而不是什么没有发生</div></li></ul><li><div>8）优先级和严重程度</div></li><ul><li><div>缺陷优先级是指缺陷必须被修复的紧急程度，而缺陷严重程度是指因缺陷引起的故障对软件产品的影响程度</div></li><li><div>严重程度是缺陷本身的属性，通常确定后就不再变化，而优先缘是缺陷的工程属性，会随着项目进度、解决缺陷的成本等因素而变动</div></li><li><div>缺陷越严重，优先级就越高</div></li><li><div>缺陷影响的范围越大，优先级也会越高</div></li><li><div>有些缺陷虽然从用户影响角度来说不算严重，但是会妨碍测试或自动化测试的执行，这类属于典型的严重程度低但优先级高</div></li><li><div>有些缺陷虽然严重程度比较高，但是考虑到修复成本及技术难度，也会出现优先级较低的情况</div></li></ul><li><div>9）变通方案（Workaround）：一种临时绕过当前缺陷而不影响开发功能的方式</div></li><li><div>10）根原因分析（Root Cause Analysis）</div></li><ul><li><div>简称RCA，如果你能在发现缺陷的同时，定位出问题的根本原因，清楚地描述缺陷产生的原因并反馈给开发工程师，那么开发工程师修复缺陷的效率就会大幅提升</div></li></ul><li><div>11）附件：截图、日志、视频等</div></li></ul><div><br/></div><div>测试计划：</div><ul><li><div>1）测试范围：明确“测什么”和“不测什么”</div></li><li><div>2）测试策略的话题：明确“先测什么后测什么”和“如何来测”</div></li><li><div>3）测试资源：明确“谁来测”和“在哪里测”</div></li><li><div>4）测试进度：描述各类测试的开始时间，所需工作量，预计完成时间，并以此为依据来建议最终产品的上线发布时间</div></li><li><div>5）测试风险预估：在制定测试计划时，预估整个测试过程中可能存在的潜在风险，以及当这些风险发生时的应对策略</div></li></ul><div><br/></div><div>开发工程师和测试工程师对知识的要求：开发工程师通常是“深度遍历”，关注的是“点”；测试工程师通常是“广度遍历”，关注的是“面”</div><div><br/></div><div>通常情况下，互联网产品要求全回归测试的执行时间不能超过4小时</div><div><br/></div><div>互联网产品的GUI测试通常采用“手工为主，自动化为辅”的测试策略，手工测试往往利用探索性测试思想，针对新开发或者修改的界面功能进行测试，而自动化测试的关注点主要放在相对稳定且核心业务的基本功能验证上。所以，GUI的自动仳测试往往只覆盖最核心且直接影响主营业务流程的E2E场景</div><div><br/></div><div>对于互联网产品来说，把测试重点放在API测试上，才是最明智的选择：</div><ul><li><div>1）API测试用例的开发与调试效率比GUI测试要高得多，而且测试用例的代码实现比较规范，通常就是准备测试数据，发起request，验证response这几个标准步骤</div></li><li><div>2）API测试用例的执行稳定性远远高于GUI测试</div></li><li><div>3）单个API测试用例的执行时间往往要比GUI测试短很多</div></li><li><div>4）现在很多互联网产品采用了微服务架构，而对微服务的测试，本质上就是对不同的Web Service的测试，也就是API的测试</div></li><li><div>5）API接口的改动一般比较少，即使有改动，绝大多数情况下也需要保证向后兼容性（Backward Compatibility）</div></li></ul><div><br/></div><div>互联网测试遵循“重量级API测试，轻量级GUI测试，轻量级单元测试”的原则</div><div><br/></div><div>互联网产品的全面单元测试只会应用在那些相对稳定和最核心的模块和服务上，而应用层或者上层业务服务很少会大规模开展单元测试</div><div><br/></div><div>数据驱动测试（Data-driven）测试：</div><ul><li><div>1）数据驱动很好地解决了大量重复脚本的问题，实现了“测试脚本和数据的解耦”，不只是CSV，还支持xls、JSON、YAML或直接数据库</div></li><li><div>2）数据驱动测试的数据文件中不仅可以包含测试输入数据，还可以包含测试验证结果数据，甚至可以包含测试逻辑分支的控制变量</div></li><li><div>3）数据驱动测试的思想不仅适用于GUI测试，还可以用于API测试、接口测试、单元测试等</div></li></ul><div><br/></div><div>页面对象（Page Object）就是利用模块化的思想，把一通用的操作集合打包成一个个名字有意义的函数，然后GUI自动化脚本直接去调用这些操作函数来构成整个测试用例，这样GUI自动化测试脚本就从原本的“流水帐”过渡到了“可重用脚本片段”</div><div><br/></div><div>页面对象模型的核心理念是，以页面（Web Page或者Native App Page）为单位来封装页面上的控件以及控件的部分操作。而测试用例，更确切地说是操作函数，基于页面封装对象来完成具体的界面操作，最典型的模式是“XXXPage.YYYComponent.ZZZOperation”</div><div><br/></div><div>操作函数的粒度是指，一个操作函数到底应该包含多少操作步骤才是最合适的。往往以完成一个业务流程（business flow）为主线，抽象出其中的“高内聚低耦合”的操作步骤集合，操作函数就由这些操作步骤集合构成</div><div><br/></div><div>业务流程抽象是，基于操作函数的更接近于实际业务的更高层次的抽象方式。基于业务流程抽象实现的测试用例往往灵活性会非常好，你可以很方便地组装出各种测试用例</div><div><br/></div><div>业务流程抽象的优点：</div><ul><li><div>1）业务流程（Business Flow）的封装更接近实际业务</div></li><li><div>2）基于业务流程的测试用例非常标准仳，遵循“参数准备”、“实例化Flow”和“执行Flow”这三大步骤，非常适用于测试代码的自动生成</div></li><li><div>3）更接近实际业务，所以可以很方便地和BDD结合</div></li></ul><div><br/></div><div>从创建的技术手段上来讲，创建测试数据的方法主要分三种：</div><ul><li><div>1）API调用</div></li><li><div>2）数据库操作</div></li><li><div>3）综合运用API调用和数据库操作</div></li></ul><div><br/></div><div>从创建的时机来讲，创建测试数据的方法主要分为两种：</div><ul><li><div>1）测试用例执行过程中，实时创建测试数据，称为On-the-fly</div></li><li><div>2）测试用例执行前，事先创建好“开箱即用”的测试数据，称为Out-of-box</div></li></ul><div><br/></div><div>在实际项目中，对于创建数据的技术手段来说，最佳选择是利用API来创建数据，只有当API不能满足数据创建的需求时，才会使用数据库操作的手段。实际上，很多测试数据是基于API和数据库操作两者结合来完成的，即先通过API创建基本的数据，然后调用数据库操作来修改数据，以达到对测试数据的特定要求</div><div><br/></div><div>对于创建数据的时机，在实际项目中，往往是On-the-fly和Out-of-box结合在一起使用。对于稳定的测试，比如商品类型、图书类型等，往往采用Out-of-box的方式以提高效率；而对于那些只能一次性使用的测试数据，比如商品、订单、优惠券等，往往采用On-the-fly的方式以保证不存在脏数据问题</div><div><br/></div><div>当你要创建一种特定的测试数据时，你发现没有直接API支持，但是可以通过API先创建一个基本的数据，然后再通过修改数据库的方式来更新这个数据，以此来达到创建特定测试数据的要求</div><div><br/></div><div>页面对象自动生成技术，属于典型的“自动化你的自动化”的应用场景。它的基本思路是，你不用再手工维护Page Class了，只需要提供Web的URL，它就会自动帮你生成这个页面上所有的控件的定位信息，并自动生成Page Class。但是，那些依赖于数据的动态页面对象会会被包含在自动生成的Page Class里，而这种动态页面对象通常不应该包含在Page Class里，所以，往往需要以手工方式删除。开源的自动化方案，页面对象自动生成功能一般需要自己开发，并且需要与你所用的自动化测试框架深度绑定，中小企业很难实现。免费的Katalon Studio可以实现。</div><div><br/></div><div>GUI测试数据自动生成：</div><ul><li><div>1）根据GUI输入数据类型，以及对应的自定义规则库自动生成测试输入数据</div></li><li><div>2）对于需要组合多个测试输入数据的场景，测试数据自动生成可以自动完成多个测试数据的笛卡尔积组合，然后再以人工的方式剔除掉非法的数据组合</div></li></ul><div><br/></div><div>无头浏览器，其实是一个特殊的浏览器，你可以把它简单地想象成是运行在内存中的浏览。它拥有完整的浏览器内核，包括JavaScript解析引擎、渲染引擎等。执行过程中看不到运行的界面，但是依然可以用GUI测试框架的截图功能截取它执行中的页面（Google发布的Headless Chrome）</div><div><br/></div><div>无头浏览器的缺点是，不能完全模拟真实用户的行为，而且由于没有实际完成页面的渲染，所以不太适用于需要对于页面布局进行验证的场景。同时，业界也一直缺乏理想的无头浏览器方案</div><div><br/></div><div>虽然从理论上来讲，GUI测试有可能做到100%稳定，但在实际项目中，这是一个几乎无法达到的目标。根据我的经验，如果能够做到95%以上的稳定性，就已经非常不错了</div><div><br/></div><div>要提高GUI测试稳定性，首先你需要知道到底是什么原因引起的不稳定。你必须找出尽可能多的不稳定因素，然后找到每一类不稳定因素对应的解决方案</div><div><br/></div><div>五种造成GUI测试不稳定的因素：</div><ul><li><div>1）非预计的弹出对话框</div></li><li><div>2）页面控件属性的细微变化</div></li><li><div>3）被测系统的A/B测试</div></li><li><div>4）随机的页面延迟造成控件识别失败</div></li><li><div>5）测试数据问题</div></li></ul><div><br/></div><div>采用“组合属性”定位控件会更精准，而且成功率会更高，如果能在此基础上加入“模糊匹配”技术，可以进一步提高控件的识别率</div><div><br/></div><div>理想中的GUI测试报告应该是由一系列按时间顺序排列的屏幕截图组成，并且这些截图上可以高亮显示所操作的元素，同时按照执行顺序配有相关操作步骤的详细描述</div><div><br/></div><div>对于大型网站来讲，GUI自动化测试往往应该做得比较轻量级，而不应该把大量的功能测试，以及功能的组合测试放在GUI自动化测试中</div><div><br/></div><div>移动测试6个专项测试：</div><ul><li><div>1）兼容性测试，通常都需要在各种真机上执行相同或者类似的测试用例，所以往往采用自动仳测试的手段。大公司会基于Appium+Selenium Grid+OpenSTF去搭建自己的移动设备私有云平台外，其他公司一般都会使用第三方的移动设备云测平台完成兼容性测试</div></li><li><div>2）交叉事件测试：如应用运行中来电话、发短信，一般手工并在真机上测试</div></li><li><div>3）流量测试，往往借助于Android和IOS自带的工具进行流量统计，也可以利用tcpdump、Wireshark和Fiddler等网络工具</div></li><li><div>4）耗电量测试：在功能类似的情况下，你的App特别耗电、让设备发比较严重，那么你的用户一定会卸载你的App而改用其他的App。最典型的就是地图类应用</div></li><li><div>5）弱网络测试：移动应用的测试需要保证在复杂网络环境下的质量。具体的做法就是在测试阶段，模拟这些网络环境，在App发布前尽可能多地发现并修复问题。Facebook的Augmented Traffic Control（ATC）</div></li><li><div>6）边界测试：需要找出各种临界场景，如内存大于90%、存储大于95、飞行模式来回切换等</div></li></ul><div><br/></div><div>代码错误，可以分为“有特征”的错误和“无特征”的错误两大类。“有特征”的错误，可进一步分为语法特征错误、边界行为错误和经验特征错误；“无特征“的错误，主要包括算法错误和部分算法错误</div><div><br/></div><div>代码级测试方法主要分为两大类，分别是静态方法和动态方法：</div><ul><li><div>1）静态方法，就是在不实际执行代码的基础上发现代码缺陷的方法，又可以进一步细分为人工静态方法和自动静态方法</div></li><li><div>2）动态方法是指，通过实际执行代码发现代码中潜在缺陷的方法，同样可以进一步细分为人工动态方法和自动动态方法</div></li></ul><div><br/></div><div>人工静态方法三种类型：</div><ul><li><div>1）代码走查（Code Review），由开发人员检查自己的代码，尽可能多地发现各类潜在错误。由于个人能力的差异，以及开发人员的“思维惯性”，很多错误并不能在这个阶段被及时发现</div></li><li><div>2）结对编程（Pair Programming），是一种敏捷软件开发方法，一般是由两个开发人员结成对子在一台计算机上共同完成开发任务</div></li><li><div>3）同行评审（Peer Review），是指把代码递交到代码仓库，或者合并代码分支（Branch）到主干（Master）前，需要和你同技术级别或者更高技术级别的一个或多个同事对你的代码进行评审，只有通过评审后，你的代码才会被真正提交</div></li></ul><div><br/></div><div>自动静态方法：</div><ul><li><div>1）在实际工程中，企业往往会结合自己的编码规范定制规程库，并与本地IDE开发环境和持续集成的流水线进行高度整合</div></li><li><div>2）代码本地开发阶段，IDE环境就可以自动对代码实现自动静态检查；当代码递交到代码库后，CI/CD流水线也会自动触发代码静态检查，如果检测到潜在错误，就会自动邮件通知代码递交者</div></li></ul><div><br/></div><div>人工动态方法（单元测试）主要难点：</div><ul><li><div>1）单元测试用例“输入参数”的复杂性</div></li><li><div>2）单元测试用例“预期输出”的复杂性</div></li><li><div>3）关联依赖的代码不可用</div></li></ul><div><br/></div><div>单元测试的输入参数：</div><ul><li><div>1）被测试函数的输入参数</div></li><li><div>2）被测试函数内部需要读取的全局静态变量</div></li><li><div>3）被测试函数内部需要读取的类成员变量</div></li><li><div>4）函数内部调用子函数获得的数据</div></li><li><div>5）函数内部调用子函数改写的数据</div></li><li><div>6）嵌入式系统中，在中断调用中改写的数据</div></li></ul><div><br/></div><div>单元测试用例“预期输出”的复杂性，“预期输出”应该包括被测函数执行完成后所改写的所有数据，主要包括：被测函数的返回值，被测函数的输出参数，被测函数所改写的成员变量和全局变量，被测函数中进行的文件更新、数据库更新、消息队列等</div><div><br/></div><div>自动动态方法的重点是：如何实现边界测试用例的自动生成。解决这个问题最简单直接的方法是，根据被测函数的输入参数生成可能的边界值</div><div><br/></div><div>从终端用户（也就是软件系统使用者）的维度来讲，软件性能表现为用户进行业务操作时的主观响应时间。具体来讲就是，从用户在界面上完成一个操作开始，到系统把本次操作的结果以用户能察觉的方式展现出来的全部时间。对终端用户来说，这个时间越短越好</div><div><br/></div><div>从软件系统运维的角度，软件性能除了包括单个用户的响应时间外，更要关注大量用户并发访问时的负载，以及可能的更大负载情况下的系统健康状态、并发处理能力、当前部署的系统容量、可能的系统瓶颈、系统配置层面的调优、数据库的调优，以及长时间运行稳定性和扩展性</div><div><br/></div><div>目前，有些系统为了能够承载更多的并发用户，往往会牺牲等待时间而引入预期的等待机制。如，火车购票网站，就在处理极大并发用户时采用了排队机制，以尽可能提高系统容量，但却增加了用户实际感受到的响应时间</div><div><br/></div><div>从软件系统开发的角度来讲，软件性能关注的是性能相关的设计和实现细节，这几乎涵盖了软件设计和开发的全过程</div><div><br/></div><div>从性能工程 的角度看，性能测试工程师关注的是算法设计、架构设计、性能最佳实践、数据库相关、软件性能的可测试性这五大方面</div><div><br/></div><div>并发用户数，包含了业务层面和后端服务器层面的两层含义：</div><ul><li><div>1）业务层面的并发用户数，指的是实际使用系统的用户总数。但是，单靠这个指标并不能反映系统实际承载的压力，我们还要结合用户行为模型才能得到系统实际承载的压力</div></li><li><div>2）后端服务器层面的并发用户数，指的是“同时向服务器发送请求的数量”，直接反映了系统实际承载的压力</div></li></ul><div><br/></div><div>响应时间，反映了完成某个操作所需要的时间，其标准定义是“应用系统从请求发出开始，到客户端接收到最后一个字节数据所消耗的时间”，是用户视角软件性能的主要体现</div><ul><li><div>1）响应时间，分为前端展现时间和系统响应时间两部分。其中，前端时间，又称呈现时间，取决于客户端收到服务器返回的数据后渲染页面所消耗的时间；而系统响应时间，又可以进一步划分为Web服务器时间、应用服务器时间、数据库时间，以及各服务器间通信的网络时间</div></li><li><div>2）严格来讲，响应时间应该包含两层含义：技术层面的标准定义和基于用户主观感觉时间的定义。而在性能测试过程中，我们应该使用哪个层面的含义将取决于性能测试的类型。对于软件服务器端的性能测试肯定要采用标准定义，而对于前端性能评估，则应该采用用户主观感受时间的定义</div></li></ul><div><br/></div><div>吞吐量：</div><ul><li><div>1）对性能测试而言，通常用“Requests/Second”“Pages/Second”“Bytes/Second”来衡量吞吐量：</div></li><li><div>2）&quot;Bytes/Second&quot;和&quot;Pages/Second&quot;表示的吞吐量，主要受网络设置、服务器架构、应用服务器制约（HTTP或业务层面）</div></li><li><div>3）&quot;Request/Second&quot;表示的吞吐量，主要应用服务器和应用本身实现的制约（系统或网络层面）</div></li></ul><div><br/></div><div>当系统并发用户数较少时，系统的吞吐量也低，系统处于空闲状态，我们往往把这个阶段称为“空闲区间”</div><div><br/></div><div>当系统整体负载并不是很大时，随着系统并发用户数的增长，系统的吞吐量也会随之呈线性增长，我们往往把这个阶段称为“线性增长区间”</div><div><br/></div><div>随着系统并发用户数的进一步增长，系统的处理能力逐渐趋于饱和，因此每个用户的响应时间会逐渐变长。相应地，系统的整体吞吐量并不会随着并发用户数的增长而继续呈线性增长。我们往往把这个阶段称为系统的“拐点”</div><div><br/></div><div>随着系统并发用户数的增长，系统处理能力达到过饱和状态。此时，如果继续增加并发用户数，最终所有用户的响应时间会变得无限长。相应地，系统的整体吞吐量会降为零，系统处于被压垮的状态。我们往往把这个阶段称为“过饱和区间”</div><div><br/></div><div>后端性能测试负载，我们一般只会把它设计在“线性增长区间”内；而压力测试的测试负载，我们则会将它设计在系统“拐点”上下，甚至是“过饱和区间”</div><div><br/></div><div>常用性能测试方法：</div><ul><li><div>1）后端性能测试</div></li><li><div>2）前端性能测试：WebPagetest</div></li><li><div>3）代码级性能测试：通常改造现有的单元测试框架，将原本只会执行一次的单元测试用例连续执行n次，n通常是2000-5000；统计执行n次的平均时间</div></li><li><div>4）压力测试</div></li><li><div>5）配置测试</div></li><li><div>6）并发测试</div></li><li><div>7）可靠性测试</div></li></ul><div><br/></div><div>不同的性能测试方法适用于不同的应用领域去解决不同的问题，主要包括：能力验证、能力规划、性能调优、缺陷发现</div><div><br/></div><div>完整的后端性能测试应该包括性能需求获取、性能场景设计、性能测试脚本开发、性能场景实现、性能测试执行、性能结果报告分析、性能优化和再验证</div><div><br/></div><div>使用性能测试工具获得性能测试报告只是性能测试过程中的一个必要步骤而已，而得出报告的目的是让性能测试工程师去做进一步的分析，以得出最终结论，并给出性能优化的措施</div><div><br/></div><div>性能测试场景会对测试负载组成、负载策略、资源监控范围定义、终止方式，以及负载产生规划作出定义，而其中的每一项还会包含更多的内容</div><div><br/></div></div><div>测试架构：</div><div><img src="软件测试52讲【极客时间】_files/1558171837843.jpg" type="image/jpeg" data-filename="1558171837843.jpg"/></div><div><br/></div><div>大型电商测试架构：</div><div><img src="软件测试52讲【极客时间】_files/1558171924040.jpg" type="image/jpeg" data-filename="1558171924040.jpg"/></div><div><br/></div><div>用户在实际使用时，并不会连续不断地向后端服务器发起请求，在两次发起请求之间往往会有一个时间的间隔，这个时间间隔主要来自于两个方面：</div><ul><li><div>1）用户操作的人为等待时间，因为用户不可能像机器人那样快速地执行操作</div></li><li><div>2）用户可能需要先在页面上填写很多信息后才能提交操作，那么填写这些信息就需要花费一定的时间</div></li></ul><div>所以，为了让虚拟用户脚本能够更真实地模拟实际用户的行为，我们就需要在两个事务之间加入一定的等待时间。这个等待时间，就是思考时间</div><div><br/></div><div>性能基准测试，会基于固定的硬件环境和部署架构，通过执行固定的性能测试场景得到系统的性能测试报告，然后与上一版本发布时的指标进行对比，如果发现指标有“恶化”的趋势，就需要进一步排查</div><div><br/></div><div>稳定性测试，又称可靠性测试，主要是通过长时间（7*24小时）模拟被测系统的测试负载，来观察系统在长期运行过程中是否有潜在的问题。通过对系统指标的监控，稳定性测试可以发现诸如内存泄漏、资源非法占用等问题</div><div><br/></div><div>并发测试，是在高并发情况下验证单一业务功能的正确性以及性能的测试手段。高并发测试一般使用思考时间为零的虚拟用户脚本来发起具有“集合点”的测试</div><div><br/></div><div>容量规划测试，容量规划的主要目的是，解决当系统负载将要达到极限处理能力时，我们应该如何通过垂直扩展（增加单机的硬件资源）和水平扩展（增加集群中的机器数量）增加系统整体的负载处理能力的问题。随着机器数量的不断增长，总会在达到某个临界值之后，集群的整体处理能力不再继续呈现线性增长。这个临界值是多少，也需要通过容量规划测试找出来</div><div><br/></div><div>基于GUI操作生成测试数据的方法一般只用于手工测试，因为自动化测试中使用这种数据准备方法 ，基本相当于要开发一个完整的GUI自动化测试用例，代价太大</div><div><br/></div><div>为了规避在创建测试数据时过于在乎实现细节的问题，在实际工程实践中，我们往往会把调用API生成测试数据的过程封装成测试数据准备函数</div><div><br/></div><div>采用On-the-fly方式创建的数据，都是测试用例自己维护的，不会依赖于测试用例外的任何数据，从而保证了数据的准确性和可控性，最大程度地避免了出现“脏”数据的可能</div><div><br/></div><div>Out-of-box最致命的问题是“脏”数据</div><div><br/></div><div>“死水数据”是指那些相对稳定，不会在使用过程中改变状态，并且可以被多次使用的数据。比如，商品分类、商品品牌、场馆信息等。这类数据就非常适合采用Out-of-box方式来创建</div><div><br/></div><div>“活水数据”是那些只能被一次使用，或者经常会被以修改的测试数据。最典型的数据是优惠券、商品本身、订单等类似的数据，适合采用On-the-fly自维护的方式</div><div><br/></div><div>测试基础架构，指执行测试的过程中用到的所有基础设施以及相关的软件设施，也称为测试执行环境</div><div><br/></div><div>Selenium Grid：是一种可以并发执行GUI测试用例的测试执行机的集群环境，采用的是HUB和NODE模式。Selenium Hub用来管理各个Selenium Node的注册信息和状态信息，并且接收远程客户端代码的测试调用请求，并把请求命令转发给符合要求的Selenium Node执行</div><div><br/></div><div>从本质上看，探索式测试具有即兴发挥、快速实验、随时调整等特征：</div><ul><li><div>1）是一种软件测试风格，而不是一种具体的软件测试技术，强调结合当前语境与上下文选择最合适的测试技术</div></li><li><div>2）强调独立测试工程师的个人自由和责任，其目的是为了持续优化其工作的价值</div></li><li><div>3）建议在整个项目过程中，将测试相关学习、测试设计、测试执行和测试结果解读为相互支持的活动，并行执行</div></li></ul><div><br/></div><div>“探索”的过程主要基于功能需求以及非功能性需求进行扩展和延伸，期间可以采用类似“头脑风暴”的工具，比如Xmind等，帮助我们整理思路</div><div><br/></div><div>测试驱动开发：核心思想，是在开发人员实现功能代码前，先设计好测试用例的代码，然后再根据测试用例的代码编写产品的功能代码，最终目的是让开发前设计的测试用例代码都能够顺利执行通过</div><div><br/></div><div>TDD的整个过程遵循以下流程：</div><ul><li><div>1）为需要实现的新功能添加一批测试</div></li><li><div>2）运行所有测试，看看新添加的测试是否失败</div></li><li><div>3）编写实现软件新功能的实现代码</div></li><li><div>4）再次运行所有的测试，看是否有测试失败</div></li><li><div>5）重构代码</div></li><li><div>6）重复以上步骤直到所有测试通过</div></li></ul><div><br/></div><div>所谓精准测试，就是借助一定的技术手段、通过算法的辅助对传统软件测试过程进行可视化、分析以及优化的过程，可以使得测试过程可视、智能、可信和精准</div><div><br/></div><div>测试用例和被测代码的双向追溯，包括正向追溯和反向追溯：</div><ul><li><div>1）正向追溯：即通过示波器将产品代码和测试用例进行自动关联，这个关联可精确到方法或者代码块级别，关联之后，精准测试系统可以显示每个测试用例实际执行的代码</div></li><li><div>2）反向追溯：指如果我要关注程序中的某一块代码，那么就可以通过精准测试系统追溯到所有测试这块代码的测试用例</div></li></ul><div><br/></div><div>智能回归测试用例选取算法便是针对需要执行的回归测试，通过算法得出各个测试用例的权重和优先级，使得在有限的时间和人力下，能够更高效地执行测试用例</div><div><br/></div><div>渗透测试的常用方法：</div><ul><li><div>1）有针对性的测试：属于研发层面的渗透测试。参与这类测试的人员，可以得到被测内部资料，包括部署信息、网络信息、详细架构设计，甚至是产品代码</div></li><li><div>2）外部测试</div></li><li><div>3）内部测试</div></li><li><div>4）盲测</div></li><li><div>5）双盲测试</div></li></ul><div><br/></div><div>渗透测试常用工具：Nmap、Aircrack-ng、SQLmap、Wifiphisher、AppScan</div><div><br/></div><div>基于模型的测试（Model-Based-Testing，MBT）：自动化测试的一个分支，将测试用例的设计依托于被测系统的模型，并基于该模型自动生成测试用例的技术。其中，这个被测系统的模型表示了被测系统行为的预期，也可以说是代表我们对被测系统的预期</div><div><br/></div><div>开展单元测试：只会选取一些偏底层的核心应用来全面开展单元测试，而对于产品的前端代码、偏业务应用的代码，很少会执行完整意义上的单元测试</div><div><br/></div><div>缓存主要用来存储那些相对变化较少，并且遵从“二八原则”的数据。指的是80%的访问数据会集中在20%的数据上。不适合那些需要频繁修改的数据</div><div><br/></div><div>造成网站不可用的主要原因有三类：</div><ul><li><div>1）服务器硬件故障：加入必要冗余</div></li><li><div>2）发布新应用的过程：灰度发布</div></li><li><div>3）应用程序本身问题：加强应用上线前的测试，或者开启预发布验证</div></li></ul><div><br/></div><div>可伸缩性，指的是通过简单地增加硬件配置而使服务处理能力呈线性增长的能力。就是通过在应用服务器集群中增加更多的节点，来提高整个集群的处理能力</div><div><br/></div><div>可扩展性，指的是网站的架构设计能够快速适应需求变化，当需要增加新的功能实现时，对原有架构不需要做修改或者做很少修改就能够快速满足新的业务需求</div><div><br/></div><div>网站的可伸缩架构主要包含：</div><ul><li><div>1）根据功能进行物理分离来实现伸缩</div></li><li><div>2）物理分离后的单一功能通过增加或者减少硬件来实现伸缩</div></li></ul><div><br/></div><div>应用服务器可伸缩设计注意：</div><ul><li><div>1）需要通过压力测试来得出单一节点的负载承受能力</div></li><li><div>2）验证系统整体的负载承受能力，是否能够随着集群中的节点数量呈线性增长</div></li><li><div>3）集群中节点的数量是否有上限</div></li><li><div>4）新加入节点是否可以提供和原来节点无差异的服务</div></li><li><div>5）对于有状态的应用，是否能够实现一次会话（session）的多次请求都被分配到集群中某一台固定的服务器上</div></li><li><div>6）验证负载均衡算法的准确性</div></li></ul><div><br/></div><div>缓存集群的可伸缩设计注意：</div><ul><li><div>1）针对缓存集群中新增节点的测试，验证其对原有缓存的影响是否足够小</div></li><li><div>2）验证系统冷启动完成后，缓存中还没有任何数据的时候，如果此时网站负载较大，数据库是否可以承受这样的压力</div></li><li><div>3）需要验证各种情况下，缓存数据和数据库数据的一致性</div></li><li><div>4）验证是否已经对潜在的缓存穿透攻击进行了处理，因为如果有人刻意利用这个漏洞来发起少量请求的话，就有可能会拖垮数据库</div></li></ul><div><br/></div><div>数据库的可伸缩性注意：</div><ul><li><div>1）正确读取到刚写入数据的延迟时间</div></li><li><div>2）在数据库架构发生改变，或者同样的架构数据库参数发生了改变时，数据库基准性能是否会发生明显的变化</div></li><li><div>3）压力测试过程中，数据库服务器的各项监控指标是否符合预期</div></li><li><div>4）数据库在线扩容过程中对业务的影响程度</div></li><li><div>5）数据库集群中，某个节点由于硬件故障对业务的影响程度</div></li></ul><div><br/></div><div>提升网站可扩展性的核心，就是降低系统各个模块和组件之间的耦合，包括事件驱动架构和微服务架构</div><div><br/></div><div>引入消息队列后注意：</div><ul><li><div>1）从构建测试数据的角度看，为了以解耦的方式测试系统的各个模块，我们就需要在消息队列中构造测试数据</div></li><li><div>2）从测试验证的角度来看，我们不仅需要验证模块的行为，还要验证模块在消息队列中的输出是否符合预期</div></li><li><div>3）从测试设计的角度来看，我们需要考虑消息队列满、消息队列扩容等情况下系统功能是否符合设计预期</div></li><li><div>4）还需要考虑某个消息队列服务器宕机的情况下，丢失消息的可恢复性以及新的消息不会继续发往宕机的服务器等等</div></li></ul><div><br/></div><div>全链路压测，是基于真实的生产环境来模拟少量的并发用户请求和数据，对整个业务链路进行压力测试，试图找到所有潜在性能瓶颈点并持续优化的实践</div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></div><div><br/></div></span>
</div></body></html> 